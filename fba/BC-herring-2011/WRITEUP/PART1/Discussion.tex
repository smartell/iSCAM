%!TEX root = /Users/stevenmartell/Documents/CURRENT PROJECTS/iSCAM-trunk/fba/BC-herring-2011/WRITEUP/BCHerring2011.tex

\section{Discussion}

%Points to make
% Highlight the major changes in this years model incomparison to the previous HCAM Model and discuss the subtle differences.

% Discuss the integrated approach to estimating the stock-recruitment model parameters and moving towards the SSF. SPecific issues regarding the definition of MSY based referece points when there are multiple gears with different selectivities.  Determining MSY implies there is an allocation framework for each of these gears.

The simulation studies showed a minor upward bias in the estimates of \fmsy, MSY and a slight bias in steepness.  Unfortunately, the true parameter values used in the simulation study did not provide significant contrast in the data to generate information over a wide range of spawning depletion.  In general, such widely contrasting data are required to resolve parameter confounding \citep{hilborn1992quantitative}.  The simulated fishing mortality rates were extremely low (i.e., less than 0.3 between 1951 and 1969, and less than 0.1 post 1970.) and the stock was never depressed to a level where, on average, recruitment would be limited by spawner abundance.  Future simulation studies should impose a more severe mortality schedule to see if this resolves the slight parameter bias.

There are a few  significant differences between  \iscam\  and the previous assessment using HCAM, despite efforts to parametrize \iscam\ as close as possible to HCAM. These differences include: different likelihood function for the age-composition data, using the conditional maximum likelihood estimate of $q$, estimation of variance, and jointly estimating parameters for the stock recruitment relationship.  Here we briefly discuss how these structural differences influence model results.

In our attempts to parametrize the \iscam\ model to reproduce the results of last years HCAM assessment, we fixed the variance and variance partitioning parameters such that the same weights were placed on the spawn observation errors and variation in annual recruitment. The age-composition data, however, were not given the same weight as the multinomial samples sizes that were used in the HCAM model. In this case, the \iscam\ model assumes a homogenous variance in the age-composition data and the weight assigned to each observation is based on the conditional maximum likelihood estimate of the variance (i.e., this is akin to using concentrated likelihoods for the age-composition data).  The main affect of this difference in likelihood formulations is that in the \iscam\ model each year is given the same weight regardless of sample size (i.e., small and large sample sizes are given too much or too little weight, respectively, in comparison to the multinomial likelihood used in HCAM).  That being said, there is also much debate about what the effective sample size should be when using the multinomial likelihood due to correlation structure in the samples \citep[e.g.,][]{francis2011data}.  Another subtle difference between the two approaches is the pooling of samples that are less than 2\% of the age-composition into the adjacent year class.


A second major difference between the two modelling platforms is the how $q$ for the dive survey data is treated.  In the previous HCAM model, the dive survey $q$ was fixed at 1, and was not treated as a latent variable.  As a result the residuals between the observed and predicted survey data did not have a mean of 0 due to contradictions between the spawn survey data and the age-composition data in the SOG assessment. The residuals for the spawn survey data post 1988 were nearly all negative.  In the \iscam\ model, the conditional maximum likelihood estimate of $q$ was used to scale the spawn survey data along with a very informative prior for $q$ was used to force $q=1$ for the post 1988 spawn survey.  In \iscam\ model the sum of the residuals between the observed and predicted spawn survey data did have a mean equal to zero and there is no apparent bias in scaling parameters ($q$'s) associated with contradictions in data sources.

In the comparison between HCAM and  \iscam\ models, the variance parameters in the \iscam\ model were fixed such that the same observation error and process error were used in both models.  The fixed variance and fixed $q$ values could also partially explain the persistent negative residual patterns observed in the HCAM model; these data may be weighted less relative to the age-composition data.  Moreover, fixing these variance parameters  (specifically the ratio of observation to process errors) is also likely to bias estimates of uncertainty in spawning biomass, and other variables.  We also explored the possibility of estimating the total variance and the fraction associated with observation error for the SOG model.  In this case, reasonable estimates of the variance parameters were obtained and this is only possible because there is information on relative abundance and age-composition in this fishery.    We further estimate all the variance parameters in Part II of this document for all major and minor stock areas.
Estimates of uncertainty are likely to be less biased now that the variance parameters are jointly estimated.

Lastly, another less subtle difference between the two modelling approaches was the estimation of the stock recruitment parameters.  In the HCAM model an improper prior was used for the steepness parameter, where steepness was bound between 0.2-0.99 and a lognormal prior was used.  In \iscam, we used a Beta distribution as the prior rescaled for values in the range of 0.2-1.0 for the Beverton-Holt model.   Estimating the stock-recruitment parameters is critical in establishing reference points and moving towards the Sustainable Fisheries Framework (SFF).  If there are no information in the data to reliably estimate steepness, then the form of the prior distribution will influence derived reference points.

The default reference points suggested in the SFF are based on the concept of Maximum Sustainable Yield (e.g., the suggested LRP is 0.4\bmsy, and the USR is 0.8\bmsy).  Such a default requires that we can accurately calculate \bmsy.  In order to calculate \bmsy, precise estimates of population parameters (\bo, $h$), life-history parameters ($M,L_\infty,k,t_o,a,b,\dot{a},\dot{\gamma}$), and  selectivity parameters ($\hat{a},\hat{\gamma}$) are required. See parameters defined in Table \ref{Table2} for a full explanation of how these are related to \bmsy.  Estimating these parameters is one of the major goals of a fisheries stock assessment model, but calculating reference points based on the concept of MSY has a potential problem when there are multiple fleets involved that have very different selectivity curves. That problem relates to allocation of yield to each of the fleets.  If each fleet has the same selectivity curve, then each fleet imposes the same age-specific mortality and there will be no impacts on the MSY estimates.  If however one or more fleets harvest fish at a much younger (or older) age, then estimates of MSY (and the corresponding removal rate reference point) will shift up or down depending on the ratio of maturity to vulnerability.  In general, the later the fish recruit to the fishing gear, the higher the sustainable fishing mortality rate.  

Calculating reference points for the SFF is more about determining allocation of herring to the purse seine and gillnet fleets.  The gillnet gear tends to catch older herring in comparison to the winter seine and seine roe fisheries.  Larger allocations to the seine fisheries come at a tradeoff of reducing potential yield for the gillnet fishery.  There is a real optimization problem here that goes just beyond the biology of the species, namely, profitability of each fishery. Furthermore, the calculation of reference points assumes that these data come from a unit-stock and not a collection of mixed sub-stocks that may differ in productivity.



